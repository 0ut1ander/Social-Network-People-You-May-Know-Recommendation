# -*- coding: utf-8 -*-
"""BigData_FriendsRecommendation_alg.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Lz8ZDgfEfpsSHcmLbMpNZn7otqyBnBIa
"""



"""# **Part - 1**"""

from pyspark import SparkContext
sc = SparkContext.getOrCreate()

lines = sc.textFile("Friends.txt")

# Map the lines into pairs of user and friends list
rdd = lines.map(lambda line: (int(line.split('\t')[0]), list(map(int, line.split('\t')[1].split(','))) if len(line.split('\t')) > 1 and line.split('\t')[1] else []))
# Cache the initial RDD to save the cost since since it's used multiple times
rdd.cache()

# calculate mutual friends excluding existing friends
def calculate_mutual_friends(user_friends_pair, existing_friends_broadcast):
    user, friends = user_friends_pair
    for friend in friends:
        for mutual_friend in friends:
            if friend < mutual_friend:
                # Check if the pair is not an existing friendship
                if (friend, mutual_friend) not in broadcast_existing_friends.value:
                    yield ((friend, mutual_friend), 1)

# generate existing friendships and broadcast the them
existing_friends = rdd.flatMap(lambda x: [(min(x[0], friend), max(x[0], friend)) for friend in x[1]]).distinct()
broadcast_existing_friends = sc.broadcast(set(existing_friends.collect()))
# if i use this below instead of the line above, there will be an error, but it's opposite in the algorithm 2, no idea why
#existing_friends_dict = existing_friends.collectAsMap()
#broadcast_num_friends = sc.broadcast(existing_friends_dict)

# find mutual friends for each pair of users
mutual_friends_rdd = rdd.flatMap(lambda pair: calculate_mutual_friends(pair, broadcast_existing_friends))

# Reducebykey to calculate the numbers of mutual friends
friendship_score_rdd = mutual_friends_rdd.reduceByKey(lambda a, b: a + b)

# map for sorting
user_pair_score_rdd = friendship_score_rdd.flatMap(lambda x: [((x[0][0], (x[0][1], x[1]))), ((x[0][1], (x[0][0], x[1])))])

# Groupbykey and sort by descending order
grouped_sorted_rdd = user_pair_score_rdd.groupByKey().mapValues(lambda x: sorted(list(x), key=lambda y: (-y[1], y[0])))

# Create an RDD with all users and their friends list
all_users_rdd = rdd.map(lambda x: (x[0], []))

# Union the RDD with recommendations and the RDD with all users to include users with no friends
# useing union may prelong the running time and increase the cost, but I didn't find better solution to include the users who has no friends
all_users_with_recommendations_rdd = grouped_sorted_rdd.union(all_users_rdd)

# Reducebykey to eliminate duplicates and take the recommendations if present
final_recommendations_rdd = all_users_with_recommendations_rdd.reduceByKey(lambda x, y: x if x else y)

# Map to include top N recommendations or empty list if no recommendations
N = 10
top_recommendations_rdd = final_recommendations_rdd.mapValues(lambda x: x[:N] if x else [])

# format the recommendations
def format_recommendations(user_recommendations):
    user, recommendations = user_recommendations
    recommended_users = ','.join(str(pair[0]) for pair in recommendations)
    return f"{user}\t{recommended_users}"

# save the output to a text file
formatted_recommendations_rdd = top_recommendations_rdd.map(format_recommendations)
final = formatted_recommendations_rdd.repartition(1)
final.saveAsTextFile("part5_output_1")

"""# **Part - 2**"""

## NOTE: this cell need to be runed after running the part 5-1 (above cell), cause it needs an argument from that cell: broadcast_existing_friends ##

from pyspark import SparkContext
sc = SparkContext.getOrCreate()

def calculate_mutual_friends(user_friends_pair, existing_friends_broadcast, num_friends_broadcast):
    user, friends = user_friends_pair
    for friend in friends:
        for mutual_friend in friends:
            if friend < mutual_friend:  # This ensures each pair is only considered once
                if (friend, mutual_friend) not in broadcast_existing_friends.value:
                    # Calculate the influence score for the mutual friend
                    part_score = 1 / num_friends_broadcast.value.get(user)
                    yield ((friend, mutual_friend), part_score)

# Calculate the number of friends for each user
num_friends = rdd.flatMap(lambda x: [(friend, 1) for friend in x[1]]).reduceByKey(lambda a, b: a + b)
#broadcast_num_friends = sc.broadcast(set(num_friends.collect()))
num_friends_dict = num_friends.collectAsMap()
broadcast_num_friends = sc.broadcast(num_friends_dict)

lines = sc.textFile("Friends.txt")
rdd = lines.map(lambda line: (int(line.split('\t')[0]), list(map(int, line.split('\t')[1].split(','))) if len(line.split('\t')) > 1 and line.split('\t')[1] else []))
# Cache the initial RDD to save the cost since since it's used multiple times
rdd.cache()

# Use the new calculate_mutual_friends function with the influence score
mutual_friends_rdd = rdd.flatMap(lambda pair: calculate_mutual_friends(pair, broadcast_existing_friends, broadcast_num_friends))

# Reduce by key to sum the influence scores for each user pair
influnce_score_rdd = mutual_friends_rdd.reduceByKey(lambda a, b: a + b)

# Map for grouping: since the pairs are mutual(2 uses has same influnce score mutually), seperate 1 tuple into 2 could save some costs
user_pair_score_rdd = influnce_score_rdd.flatMap(lambda x: [((x[0][0], (x[0][1], x[1]))), ((x[0][1], (x[0][0], x[1])))])

# Group by user1 and sort the recommendations by influence score in descending order
grouped_sorted_rdd = user_pair_score_rdd.groupByKey().mapValues(lambda x: sorted(list(x), key=lambda y: (-y[1], y[0])))

# Union with all users RDD to include users with no recommendations
all_users_rdd = rdd.map(lambda x: (x[0], []))
all_users_with_recommendations_rdd = grouped_sorted_rdd.union(all_users_rdd)

# Reduce by key to get the final recommendations
final_recommendations_rdd = all_users_with_recommendations_rdd.reduceByKey(lambda x, y: x if x else y)

# Map to get the top N recommendations based on the influence score
N = 10
top_recommendations_rdd = final_recommendations_rdd.mapValues(lambda x: x[:N] if x else [])

# format the recommendations
def format_recommendations(user_recommendations):
    user, recommendations = user_recommendations
    recommended_users = ','.join(str(pair[0]) for pair in recommendations)
    return f"{user}\t{recommended_users}"

# save the output to a text file
formatted_recommendations_rdd = top_recommendations_rdd.map(format_recommendations)
finalfile = formatted_recommendations_rdd.repartition(1)
finalfile.saveAsTextFile("part5_output_2")